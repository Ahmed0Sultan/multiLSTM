{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create custom word2vec embeddings\n",
    "\n",
    "use a mix of in-domain data (= the merged corpus sentences) and general domain data from the Brown corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derek/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataset import get_vocab, index_sents\n",
    "from embedding import create_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in-domain text - lowercased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in in-domain text, POS-tags\n",
    "alltoks = pickle.load(open('../00_data/snips/train_sents.pkl', 'rb'))\n",
    "alltags = pickle.load(open('../00_data/snips/train_tags.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_toks = []\n",
    "for seq in alltoks:\n",
    "    seq = [str(s) for s in seq]\n",
    "    if len(seq) > 1:\n",
    "        string_toks.append(' '.join(seq).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_tags = []\n",
    "for seq in alltags:\n",
    "    seq = [str(s) for s in seq]\n",
    "    if len(seq) > 1:\n",
    "        string_tags.append(' '.join(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13784"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(string_toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## supplement with generic text - lowercased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12403"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brownsents = brown.sents(categories=['news', 'editorial', 'reviews', 'government'])\n",
    "brownsents = [' '.join(s).lower() for s in brownsents]\n",
    "brownsents = [s.replace(',', '').replace('!', '').replace('?', '').replace('.', '').replace(':', '') for s in brownsents]\n",
    "len(brownsents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_text = brownsents + string_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29894,\n",
       " [('the', 24754),\n",
       "  ('of', 11817),\n",
       "  ('to', 9711),\n",
       "  ('a', 9651),\n",
       "  ('in', 8748),\n",
       "  ('and', 7596),\n",
       "  ('for', 5714),\n",
       "  ('is', 4286),\n",
       "  ('at', 3407),\n",
       "  ('on', 2852)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_lists = [s.split() for s in sentence_text]\n",
    "vocab = [w for s in sent_lists for w in s]\n",
    "from collections import Counter\n",
    "vset = set(vocab)\n",
    "vcount = Counter(vocab)\n",
    "len(vset), vcount.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence embeddings\n",
    "\n",
    "with open('../00_data/embeddings/snips_text.txt', 'w') as f:\n",
    "    for s in sentence_text:\n",
    "        f.write(s)\n",
    "        f.write('\\n')\n",
    "\n",
    "w2v_vocab, w2v_model = create_embeddings('../00_data/embeddings/snips_text.txt',\n",
    "                       embeddings_path='../00_data/embeddings/snips_embeddings.gensimmodel',\n",
    "                       vocab_path='../00_data/embeddings/snips_mapping.json',\n",
    "                       min_count=1,\n",
    "                       workers=4,\n",
    "                       size = 300,\n",
    "                       iter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derek/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('music', 0.8984863758087158),\n",
       " ('plkay', 0.8885617852210999),\n",
       " ('bundrick', 0.881790041923523),\n",
       " ('song', 0.8685442209243774),\n",
       " ('aitken', 0.8653161525726318),\n",
       " ('laurel', 0.8648514151573181),\n",
       " ('jpop', 0.8640094995498657),\n",
       " ('formalities', 0.8636695146560669),\n",
       " ('siouxsie', 0.8613051176071167),\n",
       " ('boyett', 0.857239842414856)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar('play')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derek/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cineexport', 0.9186242818832397),\n",
       " ('schedule', 0.902472198009491),\n",
       " ('maltio', 0.8923336267471313),\n",
       " ('castolon', 0.8736733198165894),\n",
       " ('nearest', 0.8685910701751709),\n",
       " ('closest', 0.8668645620346069),\n",
       " ('schedules', 0.8630369901657104),\n",
       " ('greensburg', 0.858954906463623),\n",
       " ('looking', 0.8565113544464111),\n",
       " ('kenedy', 0.8554991483688354)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar('movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas",
   "language": "python",
   "name": "atlas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
