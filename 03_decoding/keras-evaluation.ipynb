{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decode some test sentences\n",
    "\n",
    "save as a csv file for reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/derek/anaconda3/envs/kerasCRF/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from dataset import index_sents\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.preprocessing import one_hot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model, Sequential, model_from_json\n",
    "from keras.models import load_model\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers import Activation, concatenate, Dense, Input, LSTM, Dropout, Embedding\n",
    "from keras.models import save_model, load_model\n",
    "from attention import Attention\n",
    "from keras_contrib.layers import CRF\n",
    "from keras_contrib.utils import save_load_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...data loaded!\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "word2idx = np.load('../00_data/encoded/word2idx.npy').item()\n",
    "idx2word = np.load('../00_data/encoded/idx2word.npy').item()\n",
    "pos2idx = np.load('../00_data/encoded/pos2idx.npy').item()\n",
    "idx2pos = np.load('../00_data/encoded/idx2pos.npy').item()\n",
    "ner2idx = np.load('../00_data/encoded/ner2idx.npy').item()\n",
    "idx2ner = np.load('../00_data/encoded/idx2ner.npy').item()\n",
    "\n",
    "sa2idx = np.load('../00_data/encoded/sa2idx.npy').item()\n",
    "idx2sa = np.load('../00_data/encoded/idx2sa.npy').item()\n",
    "top2idx = np.load('../00_data/encoded/top2idx.npy').item()\n",
    "idx2top = np.load('../00_data/encoded/idx2top.npy').item()\n",
    "\n",
    "X_tokens = list(np.load('../00_data/encoded/add_tokens.npy'))\n",
    "X_postags = list(np.load('../00_data/encoded/add_postags.npy'))\n",
    "y_nertags = list(np.load('../00_data/encoded/add_nertags.npy'))\n",
    "\n",
    "# change category label here\n",
    "y_speechacts = np.load('../00_data/encoded/add_speechacts.npy')\n",
    "y_topics = np.load('../00_data/encoded/add_topics.npy')\n",
    "print(\"...data loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top2idx.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer-index data\n",
    "X_tokens = index_sents(X_tokens, word2idx)\n",
    "X_postags = index_sents(X_postags, pos2idx)\n",
    "y_nertags = index_sents(y_nertags, ner2idx)\n",
    "\n",
    "# integer-index and one-hot speech-acts\n",
    "INT_VOCAB = len(list(idx2sa.keys()))\n",
    "y_ints = y_speechacts[:]\n",
    "y_speechacts = one_hot([sa2idx[sa] for sa in y_speechacts], dtype='int', num_labels=INT_VOCAB)\n",
    "\n",
    "TOP_VOCAB = len(list(idx2top.keys()))\n",
    "y_tops = y_topics[:]\n",
    "y_topics = one_hot([top2idx[t] for t in y_topics], dtype='int', num_labels=TOP_VOCAB)\n",
    "\n",
    "# split data\n",
    "split_idx = int(len(X_tokens)*0.9)\n",
    "X_train_sents = X_tokens[:split_idx]\n",
    "X_train_pos = X_postags[:split_idx]\n",
    "y_train_ner = y_nertags[:split_idx]\n",
    "X_test_sents = X_tokens[split_idx:]\n",
    "X_test_pos = X_postags[split_idx:]\n",
    "y_test_ner = y_nertags[split_idx:]\n",
    "\n",
    "y_decode_ints = y_ints[split_idx:]\n",
    "y_train_sacts = y_speechacts[:split_idx]\n",
    "y_test_sacts = y_speechacts[split_idx:]\n",
    "\n",
    "y_decode_tops = y_tops[split_idx:]\n",
    "y_train_tops = y_topics[:split_idx]\n",
    "y_test_tops = y_topics[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network hyperparameters\n",
    "MAX_LENGTH = 20\n",
    "MAX_VOCAB = len(word2idx.keys())\n",
    "EMBEDDING_SIZE = 160 # preprocessing.ipynb\n",
    "POSBEDDING_SIZE = 32\n",
    "HIDDEN_SIZE = 192    # LSTM Nodes/Features/Dimension\n",
    "BATCH_SIZE = 16\n",
    "DROPOUTRATE = 0.33\n",
    "MAX_EPOCHS = 12      # max iterations, early stop condition below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero-padding sequences...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"zero-padding sequences...\\n\")\n",
    "X_train_sents = sequence.pad_sequences(X_train_sents, maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
    "X_test_sents = sequence.pad_sequences(X_test_sents, maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
    "X_train_pos = sequence.pad_sequences(X_train_pos, maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
    "X_test_pos = sequence.pad_sequences(X_test_pos, maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
    "y_train_ner = sequence.pad_sequences(y_train_ner, maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
    "y_test_ner = sequence.pad_sequences(y_test_ner, maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
    "\n",
    "# get the size of pos-tags, ner tags\n",
    "TAG_VOCAB = len(list(idx2pos.keys()))\n",
    "NER_VOCAB = len(list(idx2ner.keys()))\n",
    "\n",
    "# reshape data for CRF\n",
    "# y_train_ner = y_train_ner[:, :, np.newaxis]\n",
    "# y_test_ner = y_test_ner[:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load weights\n",
    "\n",
    "load it this way because of `keras-contrib` CRF layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Building model...\\n')\n",
    "\n",
    "# text layers : dense embedding > dropout > bi-LSTM\n",
    "txt_input = Input(shape=(MAX_LENGTH,), name='txt_input')\n",
    "txt_embed = Embedding(MAX_VOCAB, EMBEDDING_SIZE, input_length=MAX_LENGTH,\n",
    "                      name='txt_embedding', trainable=False, mask_zero=True)(txt_input)\n",
    "txt_drpot = Dropout(DROPOUTRATE, name='txt_dropout')(txt_embed)\n",
    "txt_lstml = Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True),\n",
    "                          name='txt_bidirectional')(txt_drpot)\n",
    "\n",
    "# pos layers : dense embedding > dropout > bi-LSTM\n",
    "pos_input = Input(shape=(MAX_LENGTH,), name='pos_input')\n",
    "pos_embed = Embedding(TAG_VOCAB, POSBEDDING_SIZE, input_length=MAX_LENGTH,\n",
    "                      name='pos_embedding', trainable=True, mask_zero=True)(pos_input)\n",
    "pos_drpot = Dropout(DROPOUTRATE, name='pos_dropout')(pos_embed)\n",
    "\n",
    "# merged layers : merge (concat, average...) word and pos > bi-LSTM > bi-LSTM\n",
    "mrg_cncat = concatenate([txt_lstml, pos_drpot], axis=2)\n",
    "mrg_lstml = Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True),\n",
    "                          name='mrg_bidirectional_1')(mrg_cncat)\n",
    "\n",
    "# final NER linear chain CRF layer\n",
    "crf = CRF(NER_VOCAB, sparse_target=True)\n",
    "out_ner = crf(mrg_lstml)\n",
    "\n",
    "# intent network\n",
    "rnn_intent = Attention(name='int_attention')(mrg_lstml)\n",
    "\n",
    "# intent\n",
    "dns_intent = Dense(INT_VOCAB, activation='relu', name='int_dense_1')(rnn_intent)\n",
    "dns_intent = Dense(INT_VOCAB, name='int_dense_2')(dns_intent)\n",
    "out_intent = Activation('softmax', name='int_output')(dns_intent)\n",
    "\n",
    "# topic\n",
    "dns_top = Dense(TOP_VOCAB, activation='relu', name='top_dense_1')(rnn_intent)\n",
    "dns_intent = Dense(INT_VOCAB, name='int_dense_2')(dns_top)\n",
    "out_top = Activation('softmax', name='top_output')(dns_top)\n",
    "\n",
    "model = Model(inputs=[txt_input, pos_input], outputs=[out_ner, out_intent, out_top])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "txt_input (InputLayer)           (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "txt_embedding (Embedding)        (None, 20, 160)       305280      txt_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "pos_input (InputLayer)           (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "txt_dropout (Dropout)            (None, 20, 160)       0           txt_embedding[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "pos_embedding (Embedding)        (None, 20, 32)        1248        pos_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "txt_bidirectional (Bidirectional (None, 20, 384)       542208      txt_dropout[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "pos_dropout (Dropout)            (None, 20, 32)        0           pos_embedding[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 20, 416)       0           txt_bidirectional[0][0]          \n",
      "                                                                   pos_dropout[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "mrg_bidirectional_1 (Bidirection (None, 20, 384)       935424      concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "int_attention (Attention)        (None, 384)           148224      mrg_bidirectional_1[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "int_dense_1 (Dense)              (None, 58)            22330       int_attention[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "int_dense_2 (Dense)              (None, 58)            3422        int_dense_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "top_dense_1 (Dense)              (None, 39)            15015       int_attention[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "crf_1 (CRF)                      (None, 20, 11)        4378        mrg_bidirectional_1[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "int_output (Activation)          (None, 58)            0           int_dense_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "top_output (Activation)          (None, 39)            0           top_dense_1[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 1,977,529\n",
      "Trainable params: 1,672,249\n",
      "Non-trainable params: 305,280\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "save_load_utils.load_all_weights(model,'../00_data/model/alt_combo_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = []\n",
    "\n",
    "ner_accs = []\n",
    "int_accs = []\n",
    "top_accs = []\n",
    "\n",
    "int_prds = []\n",
    "int_trus = []\n",
    "\n",
    "top_prds = []\n",
    "top_trus = []\n",
    "\n",
    "for sent_idx in range(len(X_test_sents)):\n",
    "    \n",
    "    this_txt = sequence.pad_sequences([X_test_sents[sent_idx]], maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
    "    this_pos = sequence.pad_sequences([X_test_pos[sent_idx]], maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
    "    this_pred = model.predict([this_txt, this_pos])\n",
    "    \n",
    "    this_nerpred = list(this_pred[0])\n",
    "    this_intpred = this_pred[1]\n",
    "    this_toppred = this_pred[2]\n",
    "    \n",
    "    this_nerpred = [np.argmax(p) for p in this_nerpred[0]]\n",
    "    this_intpred = np.argmax(this_intpred[0])\n",
    "    this_toppred = np.argmax(this_toppred[0])\n",
    "    \n",
    "    \n",
    "    # print(np.shape(this_nerpred), '\\n', this_nerpred, '\\n', np.shape(this_intpred), '\\n', this_intpred)\n",
    "    # print(this_nerpred, '\\n', this_intpred)\n",
    "    \n",
    "    word, pos, tru, prd = [], [], [], []\n",
    "\n",
    "    # for each word in the sentence...\n",
    "    for idx, wordid in enumerate(X_test_sents[sent_idx][:len(this_nerpred)]):\n",
    "\n",
    "        # NER ACCURACY CALC\n",
    "        # disregard padding\n",
    "        if this_nerpred[idx] != 0 and y_test_ner[sent_idx][idx] != 0:\n",
    "            if this_nerpred[idx] == y_test_ner[sent_idx][idx]:\n",
    "                ner_accs.append(1.0)\n",
    "            else:\n",
    "                ner_accs.append(0.0)\n",
    "        \n",
    "        # decode word\n",
    "        word.append(idx2word[wordid])\n",
    "        # decode pos\n",
    "        pos.append(idx2pos[X_test_pos[sent_idx][idx]])\n",
    "        # decode true NER tag\n",
    "        tru.append(idx2ner[y_test_ner[sent_idx][idx]])\n",
    "        # decode prediction\n",
    "        prd.append(idx2ner[this_nerpred[idx]])\n",
    "\n",
    "    answ = pd.DataFrame(\n",
    "    {\n",
    "        'word': word,\n",
    "        'pos': pos,\n",
    "        'true': tru,\n",
    "        'pred': prd,\n",
    "        'skip' : [' ' for s in word]\n",
    "    })\n",
    "    answ = answ[['word', 'pos', 'true', 'pred', 'skip']]\n",
    "    answ = answ.T\n",
    "    decoded.append(answ)\n",
    "    \n",
    "    if this_intpred not in idx2sa.keys():\n",
    "        this_intpred = 0\n",
    "    int_trus.append(y_decode_ints[sent_idx])\n",
    "    int_prds.append(idx2sa[this_intpred])\n",
    "    if idx2sa[this_intpred] == y_decode_ints[sent_idx]:\n",
    "        int_accs.append(1.0)\n",
    "    else:\n",
    "        int_accs.append(0.0)\n",
    "\n",
    "    if this_toppred not in idx2top.keys():\n",
    "        this_toppred = 0\n",
    "    top_trus.append(y_decode_tops[sent_idx])\n",
    "    top_prds.append(idx2top[this_toppred])\n",
    "    if idx2top[this_toppred] == y_decode_tops[sent_idx]:\n",
    "        top_accs.append(1.0)\n",
    "    else:\n",
    "        top_accs.append(0.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'airline'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_decode_tops[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9968102073365231"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ner_accs)/len(ner_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9059278350515464"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(int_accs)/len(int_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9072164948453608"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(top_accs)/len(top_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             abandon       0.74      0.67      0.70        39\n",
      "               agree       1.00      0.67      0.80         6\n",
      "           apologise       1.00      1.00      1.00         2\n",
      "             approve       0.62      0.83      0.71         6\n",
      "             confirm       0.50      0.50      0.50         2\n",
      "             correct       1.00      1.00      1.00         6\n",
      "         correctSelf       0.62      0.45      0.53        11\n",
      "              direct       1.00      0.92      0.96        13\n",
      "                echo       1.00      1.00      1.00         2\n",
      "                elab       0.67      1.00      0.80         2\n",
      "         enumeration       1.00      1.00      1.00         3\n",
      "    expressAwareness       1.00      0.50      0.67         2\n",
      "expressImPossibility       1.00      1.00      1.00         4\n",
      " expressNonAwareness       1.00      1.00      1.00         3\n",
      "      expressOpinion       0.83      0.83      0.83        24\n",
      "  expressPossibility       0.95      0.97      0.96        36\n",
      "       expressRegret       1.00      1.00      1.00         9\n",
      "         expressWish       0.71      1.00      0.83        10\n",
      "               greet       1.00      1.00      1.00         2\n",
      "                hold       0.89      0.94      0.91        33\n",
      "        identifySelf       0.75      1.00      0.86         3\n",
      "                init       0.86      1.00      0.92         6\n",
      "              negate       0.00      0.00      0.00         1\n",
      "               offer       1.00      1.00      1.00         4\n",
      "             predict       0.81      0.78      0.79        32\n",
      "  predictPossibility       1.00      0.50      0.67         2\n",
      "               refer       0.87      0.94      0.91       177\n",
      "      referCondition       0.00      0.00      0.00         1\n",
      "            referOpt       1.00      1.00      1.00         1\n",
      "         referReason       1.00      1.00      1.00         1\n",
      "              reject       0.00      0.00      0.00         1\n",
      "          reqConfirm       0.96      0.76      0.85       103\n",
      "           reqDirect       0.96      1.00      0.98        67\n",
      "             reqInfo       0.93      0.88      0.91       205\n",
      "              reqOpt       0.86      1.00      0.92         6\n",
      "               state       0.93      0.94      0.93       551\n",
      "      stateCondition       0.83      0.97      0.89        35\n",
      "     stateConstraint       0.92      0.90      0.91        50\n",
      "         stateIntent       0.91      0.95      0.93        43\n",
      "            stateOpt       0.67      0.67      0.67         3\n",
      "         stateReason       0.84      1.00      0.91        16\n",
      "             suggest       0.82      0.82      0.82        17\n",
      "               thank       1.00      1.00      1.00        12\n",
      "\n",
      "         avg / total       0.91      0.91      0.90      1552\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derek/anaconda3/envs/kerasCRF/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(int_trus, int_prds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     address       0.00      0.00      0.00        10\n",
      "     airline       0.97      1.00      0.99        78\n",
      "     airport       0.00      0.00      0.00         6\n",
      "     arrival       0.99      0.97      0.98        87\n",
      "availability       0.57      1.00      0.73         4\n",
      "     booking       0.90      1.00      0.95        18\n",
      "      cancel       0.00      0.00      0.00         9\n",
      "         car       0.00      0.00      0.00         3\n",
      "     confirm       1.00      0.33      0.50         6\n",
      "  creditcard       0.85      0.89      0.87        19\n",
      "        date       0.99      0.99      0.99        67\n",
      "         day       0.99      0.99      0.99       226\n",
      "   departure       0.92      0.92      0.92        38\n",
      "    district       0.00      0.00      0.00        21\n",
      "        enum       0.91      0.96      0.94       181\n",
      "        fare       0.88      0.88      0.88        24\n",
      "        from       0.98      0.98      0.98        63\n",
      "       hotel       0.00      0.00      0.00         2\n",
      "     journey       0.95      1.00      0.97        76\n",
      "    location       0.95      0.95      0.95       124\n",
      "        miss       0.00      0.00      0.00         3\n",
      "       month       0.96      0.93      0.94        27\n",
      "        name       0.10      0.86      0.18         7\n",
      "         nan       0.00      0.00      0.00         3\n",
      "        none       0.93      0.96      0.94       275\n",
      "      number       0.97      0.86      0.91        42\n",
      "     problem       0.15      0.67      0.25         3\n",
      "    railcard       0.00      0.00      0.00        13\n",
      "      return       0.86      1.00      0.92        12\n",
      "        seat       0.94      1.00      0.97        16\n",
      "        time       0.91      0.96      0.93        72\n",
      "          to       0.00      0.00      0.00        11\n",
      "      verify       0.00      0.00      0.00         6\n",
      "\n",
      " avg / total       0.89      0.91      0.90      1552\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derek/anaconda3/envs/kerasCRF/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(top_trus, top_prds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>and</td>\n",
       "      <td>it</td>\n",
       "      <td>i</td>\n",
       "      <td>they</td>\n",
       "      <td>also</td>\n",
       "      <td>included</td>\n",
       "      <td>here</td>\n",
       "      <td>a</td>\n",
       "      <td>spirit</td>\n",
       "      <td>file</td>\n",
       "      <td>code</td>\n",
       "      <td>number</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>CC</td>\n",
       "      <td>PRP</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>PRP</td>\n",
       "      <td>RB</td>\n",
       "      <td>VBD</td>\n",
       "      <td>RB</td>\n",
       "      <td>DT</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>COM</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>COM</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "      <td>PAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skip</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2     3     4         5     6   7       8     9     10  \\\n",
       "word  and   it    i  they  also  included  here   a  spirit  file  code   \n",
       "pos    CC  PRP  VBZ   PRP    RB       VBD    RB  DT     NNP    NN    NN   \n",
       "true    O    O    O     O     O         O     O   O     COM     O     O   \n",
       "pred    O    O    O     O     O         O     O   O     COM     O     O   \n",
       "skip                                                                      \n",
       "\n",
       "          11   12   13   14   15   16   17   18   19  \n",
       "word  number  PAD  PAD  PAD  PAD  PAD  PAD  PAD  PAD  \n",
       "pos       NN  PAD  PAD  PAD  PAD  PAD  PAD  PAD  PAD  \n",
       "true       O  PAD  PAD  PAD  PAD  PAD  PAD  PAD  PAD  \n",
       "pred       O  PAD  PAD  PAD  PAD  PAD  PAD  PAD  PAD  \n",
       "skip                                                  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.to_csv('../sample_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kerasCRF",
   "language": "python",
   "name": "kerascrf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
